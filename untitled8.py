# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ktcVfY0P_qweCP9AXKUdlAnqoKlra-QB
"""

# !pip install transformers scikit-learn xgboost matplotlib seaborn --quiet

import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, classification_report, precision_score, recall_score, f1_score
from torch.utils.data import Dataset
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, BertModel
import torch.nn as nn
import xgboost as xgb
import os

os.environ["WANDB_DISABLED"] = "true"
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# STEP 2: Load Dataset
df = pd.read_csv('/content/flipkart_data (2).csv')
df['label'] = df['rating'].apply(lambda x: 1 if x >= 4 else 0)
df = df[['review', 'label']].dropna()
df = df[df['review'].str.strip().astype(bool)]  # remove empty reviews
df = df.sample(min(len(df), 5000), random_state=42).reset_index(drop=True)

# STEP 3: Tokenization & Data Preparation
train_texts, test_texts, train_labels, test_labels = train_test_split(
    df['review'].tolist(), df['label'].tolist(), test_size=0.2, random_state=42, stratify=df['label']
)
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def get_encodings(texts):
    return tokenizer(texts, truncation=True, padding='max_length', max_length=128, return_tensors='pt')

train_encodings = get_encodings(train_texts)
test_encodings = get_encodings(test_texts)

class FlipkartDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = torch.tensor(labels)
    def __getitem__(self, idx):
        item = {k: v[idx] for k, v in self.encodings.items()}
        item['labels'] = self.labels[idx]
        return item
    def __len__(self):
        return len(self.labels)

train_dataset = FlipkartDataset(train_encodings, train_labels)
test_dataset = FlipkartDataset(test_encodings, test_labels)

# STEP 4: BERT Model
model_bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=128,
    seed=42
)
trainer = Trainer(model=model_bert, args=training_args, train_dataset=train_dataset)
trainer.train()
outputs = trainer.predict(test_dataset)
bert_preds = np.argmax(outputs.predictions, axis=1)
bert_probs = torch.softmax(torch.tensor(outputs.predictions), dim=1)[:,1].numpy()
bert_acc = accuracy_score(test_labels, bert_preds)
print(f"BERT Accuracy: {bert_acc*100:.2f}%")

def plot_cm(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(4,3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"])
    plt.title(f'Confusion Matrix: {title}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

plot_cm(test_labels, bert_preds, "BERT")
print(classification_report(test_labels, bert_preds))

# STEP 5: Improved BERT + BiLSTM (replaces original BERT_BiLSTM)
class ImprovedBERT_BiLSTM(nn.Module):
    def __init__(self, hidden_size=384, num_layers=2, dropout=0.5):
        super().__init__()
        self.bert = BertModel.from_pretrained('bert-base-uncased')
        self.lstm = nn.LSTM(
            input_size=self.bert.config.hidden_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            bidirectional=True,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0,
        )
        self.layernorm = nn.LayerNorm(hidden_size * 2)
        self.dropout = nn.Dropout(dropout)
        self.classifier = nn.Linear(hidden_size * 2, 2)

    def forward(self, input_ids=None, attention_mask=None, labels=None):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        sequence_output = outputs.last_hidden_state  # (batch, seq_len, hidden)
        lstm_output, _ = self.lstm(sequence_output) # (batch, seq_len, hidden*2)
        pooled_output = lstm_output[:, -1, :]       # Take last time step
        pooled_output = self.layernorm(pooled_output)
        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        loss = None
        if labels is not None:
            loss = nn.CrossEntropyLoss()(logits, labels)
        return {'loss': loss, 'logits': logits}

improved_model_bilstm = ImprovedBERT_BiLSTM().to(device)
improved_training_args = TrainingArguments(
    output_dir='./results_bilstm',
    num_train_epochs=5,                 # Train longer for BiLSTM
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    learning_rate=2e-5,                 # Lower LR for better convergence
    weight_decay=0.01,
    seed=42,
)
trainer2 = Trainer(
    model=improved_model_bilstm,
    args=improved_training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
)
trainer2.train()
outputs2 = trainer2.predict(test_dataset)
bilstm_preds = torch.argmax(torch.tensor(outputs2.predictions), dim=1).numpy()
bilstm_probs = torch.softmax(torch.tensor(outputs2.predictions), dim=1)[:,1].numpy()
bilstm_acc = accuracy_score(test_labels, bilstm_preds)
print(f"Improved BERT+BiLSTM Accuracy: {bilstm_acc*100:.2f}%")
plot_cm(test_labels, bilstm_preds, "BERT+BiLSTM")
print(classification_report(test_labels, bilstm_preds))

# STEP 6: BERT + XGBoost (using pooled [CLS] embeddings)
bert = BertModel.from_pretrained("bert-base-uncased").to(device)
bert.eval()
with torch.no_grad():
    def get_cls_embeddings(encodings, batch_size=64):
        input_ids = encodings['input_ids'].to(device)
        attention_mask = encodings['attention_mask'].to(device)
        cls_embed = []
        for i in range(0, len(input_ids), batch_size):
            end = min(i+batch_size, len(input_ids))
            batch_ids = input_ids[i:end]
            batch_mask = attention_mask[i:end]
            output = bert(batch_ids, attention_mask=batch_mask).last_hidden_state[:, 0, :]
            cls_embed.append(output.cpu())
        return torch.cat(cls_embed).numpy()
    train_features = get_cls_embeddings(train_encodings)
    test_features = get_cls_embeddings(test_encodings)

xgb_clf = xgb.XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb_clf.fit(train_features, train_labels)
xgb_preds = xgb_clf.predict(test_features)
xgb_probs = xgb_clf.predict_proba(test_features)[:, 1]
xgb_acc = accuracy_score(test_labels, xgb_preds)
print(f"BERT+XGBoost Accuracy: {xgb_acc*100:.2f}%")
plot_cm(test_labels, xgb_preds, "BERT+XGBoost")
print(classification_report(test_labels, xgb_preds))

# STEP 7: ROC Curves
fpr_bert, tpr_bert, _ = roc_curve(test_labels, bert_probs)
fpr_bilstm, tpr_bilstm, _ = roc_curve(test_labels, bilstm_probs)
fpr_xgb, tpr_xgb, _ = roc_curve(test_labels, xgb_probs)

plt.figure(figsize=(8,6))
plt.plot(fpr_bert, tpr_bert, label=f'BERT (AUC = {auc(fpr_bert, tpr_bert):.2f})')
plt.plot(fpr_bilstm, tpr_bilstm, label=f'BERT+BiLSTM (AUC = {auc(fpr_bilstm, tpr_bilstm):.2f})')
plt.plot(fpr_xgb, tpr_xgb, label=f'BERT+XGBoost (AUC = {auc(fpr_xgb, tpr_xgb):.2f})')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.title("ROC Curves for All Models")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid(True)
plt.show()

# STEP 8: Metrics Table
def collect_metrics(y_true, y_pred, y_prob):
    return {
        "Accuracy": accuracy_score(y_true, y_pred),
        "Precision": precision_score(y_true, y_pred),
        "Recall": recall_score(y_true, y_pred),
        "F1-score": f1_score(y_true, y_pred),
        "AUC": auc(*roc_curve(y_true, y_prob)[:2])
    }

metrics = pd.DataFrame([
    collect_metrics(test_labels, bert_preds, bert_probs),
    collect_metrics(test_labels, bilstm_preds, bilstm_probs),
    collect_metrics(test_labels, xgb_preds, xgb_probs)
], index=["BERT", "BERT+BiLSTM", "BERT+XGBoost"])

print("\nModel Comparison Table:")
print(metrics.round(4))

# STEP 9: Sentiment Analysis and Visualization

def get_sentiment_label(pred, prob=None, threshold_pos=0.7, threshold_neg=0.3):
    # If 2 classes: 1 = positive, 0 = negative. Use probability for "neutral"
    if prob is not None:
        if prob >= threshold_pos:
            return "Positive"
        elif prob <= threshold_neg:
            return "Negative"
        else:
            return "Neutral"
    else:
        return "Positive" if pred == 1 else "Negative"

def plot_sentiment_breakdown(name, preds, probs=None):
    if probs is not None:
        sentiments = [get_sentiment_label(p, pr) for p, pr in zip(preds, probs)]
    else:
        sentiments = [get_sentiment_label(p) for p in preds]
    sentiment_counts = pd.Series(sentiments).value_counts().reindex(['Positive', 'Neutral', 'Negative'], fill_value=0)
    print(f"\n{name} Sentiment Breakdown:")
    for sentiment, count in sentiment_counts.items():
        print(f"{sentiment}: {count}")
    plt.figure(figsize=(5,4))
    sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette="viridis")
    plt.title(f"{name} Sentiment Distribution")
    plt.ylabel("Number of Reviews")
    plt.xlabel("Sentiment")
    plt.show()
    return sentiment_counts

# BERT Sentiment
plot_sentiment_breakdown("BERT", bert_preds, bert_probs)
# BERT+BiLSTM Sentiment
plot_sentiment_breakdown("BERT+BiLSTM", bilstm_preds, bilstm_probs)
# BERT+XGBoost Sentiment
plot_sentiment_breakdown("BERT+XGBoost", xgb_preds, xgb_probs)

